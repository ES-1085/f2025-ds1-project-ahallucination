---
title: "Project memo"
author: "Brynn Sasha & Yuka"
output: github_document
---

This document should contain a detailed account of the data clean up for your data and the design choices you are making for your plots. For instance you will want to document choices you've made that were intentional for your graphic, e.g. color you've chosen for the plot. Think of this document as a code script someone can follow to reproduce the data cleaning steps and graphics in your handout.

```{r load-packages, message = FALSE}

library(tidyverse)
library(broom)
ai_data <- read_csv("../data/Charlotin-hallucination_cases.csv")
#view(ai_data)

```

## Data Clean Up Steps for Overall Data

### Step 1: _________

```{r rename-variables}
ai_data <- as_tibble(ai_data) |>
  rename(
`case_name` = `Case Name`,
`court_location` = `Court`,
`country` = `State(s)`,
`date` = `Date`,
`party` = `Party(ies)`,
`ai_tool` = `AI Tool`,
`hallucination` = `Hallucination`,
`outcome` = `Outcome`,
`monetary_penalty` = `Monetary Penalty`,
`professional_sanction` = `Professional Sanction`,
`key_principle` = `Key Principle`,
`pointer` = `Pointer`,
`source` = `Source`,
`details` = `Details`
)
```

### Step 2:

```{r data-cleanup}
ai_data <- ai_data |>
  mutate(
    across(
      c(court_location, country, hallucination, outcome, monetary_penalty, professional_sanction),
      ~ .x |> str_squish() |> str_to_title() |> na_if("")
    )
  )
```

#### Step 3:

```{r monetary-penalty-tidy}

rates <- tibble::tribble(
  ~currency, ~rate_to_usd,
  "USD", 1,
  "EUR", 1.07,
  "GBP", 1.24,
  "CAD", 0.73
)

ai_data <- ai_data %>% 
  mutate(currency = "USD")


monetary_penalty_tidy <- ai_data %>%
  mutate(
    monetary_penalty = str_replace_all(monetary_penalty, "[$,]", ""),
    monetary_penalty = na_if(monetary_penalty, "none"),
    monetary_penalty = na_if(monetary_penalty, "n/a"),
    monetary_penalty = na_if(monetary_penalty, "na"),
    monetary_penalty = na_if(monetary_penalty, "N/A"),
    monetary_penalty = as.numeric(monetary_penalty)
  )

monetary_penalty_usd <- monetary_penalty_tidy %>%
  mutate(
    monetary_penalty_usd = if_else(str_to_upper(currency) == "USD",
                                   monetary_penalty,
                                   NA_real_)
  )
```

#### Step 4:

```{r professional-sanction-tidy}

ai_data <- ai_data |>
  mutate(
    professional_sanction = case_when(
      str_detect(professional_sanction, regex("yes|y", ignore_case = TRUE)) ~ "Yes",
      str_detect(professional_sanction, regex("no|n", ignore_case = TRUE)) ~ "No",
      TRUE ~ professional_sanction
    )
  )

```

## Plots

### ggsave example for saving plots

```{r starwars ggsave example}
p1 <- starwars |>
  filter(mass < 1000, 
         species %in% c("Human", "Cerean", "Pau'an", "Droid", "Gungan")) |>
  ggplot() +
  geom_point(aes(x = mass, 
                 y = height, 
                 color = species)) +
  labs(x = "Weight (kg)", 
       y = "Height (m)",
       color = "Species",
       title = "Weight and Height of Select Starwars Species",
       caption = paste("This data comes from the starwars api: https://swapi.py43.com"))


ggsave("example-starwars.png", width = 4, height = 4)

ggsave("example-starwars-wide.png", width = 6, height = 4)
```


### Plot 1: Trend of AI Hallucination Cases by Most Used LLM (2023-2025)

#### Plot 1 Data Cleanup

```{r ai-tool-cleanup}

### Standardizing Text
ai_tool_tidy <- ai_data |>
  mutate(ai_tool = str_replace_all(ai_tool, " and | & ", ",")) |>
  separate_rows(ai_tool, sep = ",|/|;") |>
  mutate(ai_tool = str_squish(ai_tool),
         ai_tool = na_if(ai_tool, ""),
         ai_tool = if_else(str_to_lower(ai_tool) %in% c("n/a","na","none"), NA_character_, ai_tool)) |>
  drop_na(ai_tool)

### Settings Synonyms
synonyms <- c(
  "ChatGPT" = "OpenAI ChatGPT",
  "GPT-4" = "OpenAI ChatGPT",
  "GPT4" = "OpenAI ChatGPT",
  "Google Gemini" = "Gemini",
  "Google Bard" = "Gemini",
  "Bard" = "Gemini",
  "Claude" = "Anthropic Claude",
  "implied" = "Implied",
  "Copilot" = "MS Copilot",
  "Microsoft CoPilot" = "MS Copilot",
  "CoPilot" = "MS Copilot"
)
ai_tool_tidy <- ai_tool_tidy |>
  mutate(ai_tool = coalesce(synonyms[ai_tool], ai_tool))

```

#### Final Plot 1

```{r plot-one, fig.alt = "Line graph from 2023 to 2025 of number of AI hallucination cases by the 3 most used LLM types represented by three color-coded lines. OpenAI/ChatGPT, MS Copilot, and Gemini are the three large language models plotted. Cases spike in the beginning of 2025 with OpenAI/ChatGPT cases increasing the most."}
library(tidyverse)
library(lubridate)
library(scales)

monthly_tools <- ai_data |>
  mutate(
    date  = ymd(date),
    month = floor_date(date, "month")
  ) |>
  filter(!is.na(`ai_tool`)) |>
  mutate(
    tool = case_when(
      str_detect(`ai_tool`, regex("chatgpt", ignore_case = TRUE))        ~ "OpenAI ChatGPT",
      str_detect(`ai_tool`, regex("copilot", ignore_case = TRUE))        ~ "MS Copilot",
      str_detect(`ai_tool`, regex("gemini|bard", ignore_case = TRUE))    ~ "Gemini",
      TRUE ~ NA_character_
    )
  ) |>
  filter(!is.na(tool)) |>
  count(month, tool, name = "n")

tool_order <- monthly_tools |>
  group_by(tool) |>
  summarise(total = sum(n), .groups = "drop") |>
  arrange(desc(total)) |>
  pull(tool)

monthly_tools <- monthly_tools |>
  mutate(tool = factor(tool, levels = tool_order))

max_cases <- max(monthly_tools$n, na.rm = TRUE)

ggplot(monthly_tools,
       aes(x = month, y = n, colour = tool, group = tool)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.8) +
  scale_x_date(
  date_breaks = "6 months",
    date_labels = "%Y-%m",
    expand = expansion(mult = c(0.02, 0.05))
  ) +
  scale_y_continuous(
    breaks = seq(0, max_cases, by = 2),       
    limits = c(0, max_cases),
    expand = expansion(mult = c(0.02, 0.05))
  ) +
  scale_colour_brewer(palette = "Dark2", name = "LLM Type") + 
  labs(
    title  = "Trend of AI Hallucination Cases by Most Used LLM Type(2023-2025)",
    x      = "Time Period",
    y      = "Number of Cases"
  ) +
  theme_minimal() +
  theme(
    axis.text.x  = element_text(hjust = 1),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    plot.title   = element_text(size = 14, hjust = 0.5)
  )
```

### Plot 2: AI Hallucination Cases and Corresponding Outcome by State

#### Plot 2 Data Cleanup

##### Step 1:

```{r court-location-cleanup}

ai_data <- ai_data |>
  mutate(
    court_location = case_when(
      str_detect(court_location, regex("Iowa", ignore_case = TRUE)) ~ "Iowa",
      str_detect(court_location, regex("Alabama", ignore_case = TRUE)) ~ "Alabama",
      str_detect(court_location, regex("Arizona", ignore_case = TRUE)) ~ "Arizona",
      str_detect(court_location, regex("Arkansas", ignore_case = TRUE)) ~ "Arkansas",
      str_detect(court_location, regex("California|Fifth|Cal.|3rd|Cal|2nd|9th", ignore_case = TRUE)) ~ "California",
      str_detect(court_location, regex("Colorado", ignore_case = TRUE)) ~ "Colorado",
      str_detect(court_location, regex("Connecticut", ignore_case = TRUE)) ~ "Connecticut",
      str_detect(court_location, regex("Florida", ignore_case = TRUE)) ~ "Florida",
      str_detect(court_location, regex("Georgia|Ga.", ignore_case = TRUE)) ~ "Georgia",
      str_detect(court_location, regex("Hawaii|Hawai'i", ignore_case = TRUE)) ~ "Hawaii",
      str_detect(court_location, regex("Idaho", ignore_case = TRUE)) ~ "Idaho",
      str_detect(court_location, regex("Illinois|Cook County|7th", ignore_case = TRUE)) ~ "Illinois",
      str_detect(court_location, regex("Indiana|Ind.", ignore_case = TRUE)) ~ "Indiana",
      str_detect(court_location, regex("Kansas", ignore_case = TRUE)) ~ "Kansas",
      str_detect(court_location, regex("Kentucky", ignore_case = TRUE)) ~ "Kentucky",
      str_detect(court_location, regex("Louisiana", ignore_case = TRUE)) ~ "Louisiana",
      str_detect(court_location, regex("Maine", ignore_case = TRUE)) ~ "Maine",
      str_detect(court_location, regex("Maryland", ignore_case = TRUE)) ~ "Maryland",
      str_detect(court_location, regex("Massachusetts", ignore_case = TRUE)) ~ "Massachusetts",
      str_detect(court_location, regex("Michigan|Mich.", ignore_case = TRUE)) ~ "Michigan",
      str_detect(court_location, regex("Minnesota|Minnesotta", ignore_case = TRUE)) ~ "Minnesota",
      str_detect(court_location, regex("Mississippi|Miss.", ignore_case = TRUE)) ~ "Mississippi",
      str_detect(court_location, regex("Missouri", ignore_case = TRUE)) ~ "Missouri",
      str_detect(court_location, regex("Montana", ignore_case = TRUE)) ~ "Montana",
      str_detect(court_location, regex("Nebraska", ignore_case = TRUE)) ~ "Nebraska",
      str_detect(court_location, regex("Nevada|Nev.", ignore_case = TRUE)) ~ "Nevada",
      str_detect(court_location, regex("New Hampshire", ignore_case = TRUE)) ~ "New Hampshire",
      str_detect(court_location, regex("New Mexico", ignore_case = TRUE)) ~ "New Mexico",
      str_detect(court_location, regex("New Jersey", ignore_case = TRUE)) ~ "New Jersey",
      str_detect(court_location, regex("New York|E.d.n.y.|N.y.|S.d.n.y.|Kings County|Ndny|Ny|Supreme Court, Ny|Sdny", ignore_case = TRUE)) ~ "New York",
      str_detect(court_location, regex("North Carolina|N. Carolina|N.c.", ignore_case = TRUE)) ~ "North Carolina",
      str_detect(court_location, regex("North Dakota", ignore_case = TRUE)) ~ "North Dakota",
      str_detect(court_location, regex("Ohio", ignore_case = TRUE)) ~ "Ohio",
      str_detect(court_location, regex("Oklahoma", ignore_case = TRUE)) ~ "Oklahoma",
      str_detect(court_location, regex("Oregon", ignore_case = TRUE)) ~ "Oregon",
      str_detect(court_location, regex("Pennsylvania|Penn.|Pa.", ignore_case = TRUE)) ~ "Pennsylvania",
      str_detect(court_location, regex("Rhode Island", ignore_case = TRUE)) ~ "Rhode Island",
      str_detect(court_location, regex("South Carolina|Sc|S.c.", ignore_case = TRUE)) ~ "South Carolina",
      str_detect(court_location, regex("South Dakota", ignore_case = TRUE)) ~ "South Dakota",
      str_detect(court_location, regex("Tennessee", ignore_case = TRUE)) ~ "Tennessee",
      str_detect(court_location, regex("Texas|Tex.", ignore_case = TRUE)) ~ "Texas",
      str_detect(court_location, regex("Utah", ignore_case = TRUE)) ~ "Utah",
      str_detect(court_location, regex("Vermont", ignore_case = TRUE)) ~ "Vermont",
      str_detect(court_location, regex("Virginia|Gao|Ocaho|Dc|Federal Claims|(Gao)|Tax Court|Fed. Claims|D.c.", ignore_case = TRUE)) ~ "Virginia",
      str_detect(court_location, regex("Washington", ignore_case = TRUE)) ~ "Washington",
      str_detect(court_location, regex("West Virginia", ignore_case = TRUE)) ~ "West Virginia",
      str_detect(court_location, regex("Wisconsin|Ho-Chunk", ignore_case = TRUE)) ~ "Wisconsin",
      str_detect(court_location, regex("Wyoming", ignore_case = TRUE)) ~ "Wyoming",
      str_detect(court_location, regex("Puerto Rico|Primera", ignore_case = TRUE)) ~ "Puerto Rico",
      str_detect(court_location, regex("High Court|Alberta|Frankfurt|Ontario|Family|Nsw|Buenos|Civil|Supreme|Court|Victoria|Review|Rotterdam|Icsid|Rosario|Employment|Immigration|Columbia|Paulo|Chancery|Resolution|Fair Work|Jerusalem|Ontario's|Ottawa|Intellectual|Parana|Queensland|Israel|Uk|Supremo|Housing|Olg|Crt|Florence|Australia|Constitucional|Hague|Manchester|Torino", ignore_case = TRUE)) ~ "International",
      TRUE ~ court_location
    )
  )

```

##### Step 2:

```{r outcome-cleanup}

ai_data <- ai_data |>
  mutate(
    outcome = case_when(
      str_detect(outcome, regex("Warning|Opportunity|No Contempt|Warned|Caution|Reprimand|Reminder|Refile|Corrections|Exclude|Criticised|Reprimand|Court Imposed", ignore_case = TRUE)) ~ "Warning",
      str_detect(outcome, regex("dismissed|thrown out|Accepted|Excluded|Rejected|Discharged|Dismiss|Sworn|Withdrew|Removed|Stricken|Striking|Ignored|Struck|Disregarded|Irrelevant|Dismissal|Inadmissible|Admonishment|No Weight|Striking|Adjourned|Withdrawn", ignore_case = TRUE)) ~ "Dismissed",
      str_detect(outcome, regex("pending|Under Review|Re-Heard|Osc|ongoing|Tenatively|Referral|3 hours|Referred", ignore_case = TRUE)) ~ "Pending",
      str_detect(outcome, regex("Apologize|Lost On Merits|fined|Lost|sanction|penalty|Fine|costs|Cause|cause|Pay|Costs|Costas|Denied|Community Service|Contempt|Cle Course|Reimburse|Ethics|Fine|Lesser Weight|Treated|Compensated|Liability|Refused|Suspension|Mandantory|Undergo", ignore_case = TRUE)) ~ "Penalized",
      TRUE ~ outcome
    )
  )

```

#### Final Plot 2

```{r state-pie-map, message = FALSE, warning = FALSE, fig.alt = "State Pie map of the magnitude of AI hallucination cases and corresponding outcome by state. Relative size of the pie charts correlates to the number of cases in the state. New York and California have the highest number of cases. Slices are color-coded by outcome and show the majority of New York and California's cases resulted in either a warning or penalty."}
library(dplyr)
library(tidyr)
library(ggplot2)
library(maps)
library(scatterpie)
library(stringr)
library(scales)

ai_data_outcome <- ai_data |>
  mutate(
    outcome_simple = case_when(
      outcome %in% c("Warning", "Dismissed", "Pending", "Penalized") ~ outcome,
      TRUE ~ NA_character_
    ),
    court_location = str_to_title(court_location)
  ) |>
  filter(!is.na(outcome_simple)) |>
  filter(!court_location %in% c("Hawaii", "Puerto Rico"))


state_outcome <- ai_data_outcome |>
  filter(!is.na(court_location)) |>
  count(court_location, outcome_simple, name = "n")

state_outcome_wide <- state_outcome |>
  pivot_wider(
    names_from  = outcome_simple,
    values_from = n,
    values_fill = 0
  ) |>
  mutate(total_cases = rowSums(across(-court_location)))

state_centers <- tibble::tibble(
  court_location = state.name,
  long = state.center$x,
  lat  = state.center$y
) |>
  filter(!court_location %in% c("Hawaii", "Puerto Rico"))

state_pies <- state_outcome_wide |>
  inner_join(state_centers, by = "court_location") |>
  mutate(
    radius = scales::rescale(sqrt(total_cases), to = c(0.4, 1.2))
  )

pie_cols <- c("Warning", "Dismissed", "Pending", "Penalized")

okabe_ito <- c(
  "Warning"   = "#F46D43FF", 
  "Dismissed" = "#4575B4FF", 
  "Pending"   = "#FDAE61FF", 
  "Penalized" = "#D73027FF"  
)

us_map <- map_data("state") |>
  mutate(region = str_to_title(region)) |>
  filter(!region %in% c("Hawaii"))

ggplot() +
  geom_polygon(
    data = us_map,
    aes(x = long, y = lat, group = group),
    fill = "#ABD9E9FF",
    color = "white"
  ) +
  scatterpie::geom_scatterpie(
    data = state_pies,
    aes(x = long, y = lat, r = radius),
    cols = pie_cols,
    color = NA
  ) +
  coord_fixed(1.3) +
  scale_fill_manual(
    name = "Outcome",
    values = okabe_ito
  ) +
  labs(
    title = "AI Hallucination Cases and Corresponding Outcome by State",
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5),
    plot.subtitle   = element_text(hjust = 0.5),
    legend.background     = element_rect(fill = "white", colour = "black", size = 0.3),
    legend.box.background = element_rect(fill = "white", colour = "black", size = 0.3),
    legend.key            = element_rect(fill = "white", colour = "white"),
    legend.margin         = margin(6, 6, 6, 6),
    legend.title          = element_text(face = "bold")
  )

```

### Plot 3: Top 5 Hallucination Types by Outcome

#### Plot 3 Data Cleanup

##### Step 1:

```{r hallucination-cleanup}

ai_data <- ai_data |>
  mutate(
    hallucination = case_when(
      str_detect(coalesce(hallucination, ""), regex("Miscited|Case Cited|citation|Cittions", ignore_case = TRUE)) ~ "Fake Citation",
      str_detect(coalesce(hallucination, ""), regex("Chatgpt-Generated|Irrelevant Info|Paragraph|argument|Authority",  ignore_case = TRUE)) ~ "Fake Argument",
      str_detect(coalesce(hallucination, ""), regex("Inaccuracies|Quotation|Quotations|References|quote|source|evidentiary|evidence", ignore_case = TRUE)) ~ "Fake Source/Quote",
      str_detect(coalesce(hallucination, ""), regex("Non-Existent Legal|Wrong Legal|Caselaw|case law", ignore_case = TRUE)) ~ "Fabricated Case Law",
      str_detect(coalesce(hallucination, ""), regex("norm", ignore_case = TRUE)) ~ "Fabricated Norm",
      str_detect(coalesce(hallucination, ""), regex("Fake/Incorrect|Nonexistent Cases|Non-Existent Israeli|Irrelevant Cases|Fake Legal Case|Fictitious Cases|Non-Existent Case|Or Misrepresented Cases|Non-Existent Cases|Fabricated Cases|Fake Cases|Fake Case|Fake/Flawed Cases|Fictitious Court", ignore_case = TRUE)) ~ "Fabricated Case",
      str_detect(coalesce(hallucination, ""), regex("Misrepresented Facts|Precedent", ignore_case = TRUE)) ~ "Misrepresented Fact / Precedent",
      str_detect(coalesce(hallucination, ""), regex("Legal Authorities|Fictitious Authorities|Tribunal|Outdated Advice|Fictitious Legal|Court Decisions|Misattributed Court Decisions|Fictitious Court|Fictitious Judgement|Legal Judgments|Judgements", ignore_case = TRUE)) ~ "False Legal Judgments",
      str_detect(coalesce(hallucination, ""), regex("Suspicious|Unverifiable|Allegations|Pseudolegal|None", ignore_case = TRUE)) ~ "Unable to Conclude AI-Generated Content",
      str_detect(coalesce(hallucination, ""), regex("Fabricated Attribution", ignore_case = TRUE)) ~ "Fabricated Attribution",
      str_detect(coalesce(hallucination, ""), regex("Appeal", ignore_case = TRUE)) ~ "Fake Appeal Brief",
      TRUE ~ hallucination
    )
  )

```

##### Step 2:

```{r plot-three-general-cleanup}

library(tidyverse)
library(scales)
library(forcats)


ai_data <- ai_data |>
  mutate(
    outcome = str_squish(outcome),
    outcome = na_if(outcome, "NA"),
    outcome = na_if(outcome, "N/A"),
    outcome = na_if(outcome, "None"),
    outcome = na_if(outcome, "")
  )

top5_hallucinations <- ai_data |>
  filter(!is.na(hallucination)) |>
  count(hallucination, sort = TRUE) |>
  distinct(hallucination, .keep_all = TRUE) |>
  slice_head(n = 5) |>
  pull(hallucination) |>
  unique()


hall_outcome <- ai_data |>
  filter(
    hallucination %in% top5_hallucinations,
    !is.na(outcome)
  ) |>
  droplevels() |> 
  count(outcome, hallucination, name = "n_cases") |>
  group_by(outcome) |>
  mutate(
    pct_within_outcome = n_cases / sum(n_cases),
    total_cases        = sum(n_cases)
  ) |>
  ungroup() |>
  mutate(
    hallucination = factor(hallucination,
                           levels = unique(top5_hallucinations)) 
  )

```

#### Final Plot 3

```{r plot-three, fig.alt = "Bubble map of the number of cases for each combination of the four outcomes and top five hallucination types. Color of the bubbles correspond to the type of AI hallucination and relative size of the bubbles represents the number of cases under each intersection of variables"}
ggplot(hall_outcome,
       aes(x = fct_reorder(outcome, total_cases),
           y = hallucination,
           size = n_cases,
           fill = hallucination)) +
  geom_point(shape = 21, color = "black", alpha = 0.85) +
  scale_size(range = c(3, 18), name = "Number of Cases") +
  scale_fill_viridis_d(option = "C", guide = "none") +
  labs(
    title = "Bubble Map of Top 5 Hallucination Types by Outcome",
    x = "Outcome",
    y = "Hallucination Category"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 25, hjust = 1)
  )
```



