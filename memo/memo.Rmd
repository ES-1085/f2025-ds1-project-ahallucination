---
title: "Project memo"
author: "Brynn Sasha & Yuka"
output: github_document
---

This document should contain a detailed account of the data clean up for your data and the design choices you are making for your plots. For instance you will want to document choices you've made that were intentional for your graphic, e.g. color you've chosen for the plot. Think of this document as a code script someone can follow to reproduce the data cleaning steps and graphics in your handout.

```{r load-packages, message = FALSE}

library(tidyverse)
library(broom)
ai_data <- read_csv("../data/Charlotin-hallucination_cases.csv")
#view(ai_data)

```

## Data Clean Up Steps for Overall Data

### Step 1: _________

```{r rename-variables}
ai_data <- as_tibble(ai_data) |>
  rename(
`case_name` = `Case Name`,
`court_location` = `Court`,
`country` = `State(s)`,
`date` = `Date`,
`party` = `Party(ies)`,
`ai_tool` = `AI Tool`,
`hallucination` = `Hallucination`,
`outcome` = `Outcome`,
`monetary_penalty` = `Monetary Penalty`,
`professional_sanction` = `Professional Sanction`,
`key_principle` = `Key Principle`,
`pointer` = `Pointer`,
`source` = `Source`,
`details` = `Details`
)
```

### Step 2:

```{r data-cleanup}
ai_data <- ai_data |>
  mutate(
    across(
      c(court_location, country, hallucination, outcome, monetary_penalty, professional_sanction),
      ~ .x |> str_squish() |> str_to_title() |> na_if("")
    )
  )
```

#### Step 3:

```{r monetary-penalty-tidy}

rates <- tibble::tribble(
  ~currency, ~rate_to_usd,
  "USD", 1,
  "EUR", 1.07,
  "GBP", 1.24,
  "CAD", 0.73
)

ai_data <- ai_data %>% 
  mutate(currency = "USD")


monetary_penalty_tidy <- ai_data %>%
  mutate(
    monetary_penalty = str_replace_all(monetary_penalty, "[$,]", ""),
    monetary_penalty = na_if(monetary_penalty, "none"),
    monetary_penalty = na_if(monetary_penalty, "n/a"),
    monetary_penalty = na_if(monetary_penalty, "na"),
    monetary_penalty = na_if(monetary_penalty, "N/A"),
    monetary_penalty = as.numeric(monetary_penalty)
  )

monetary_penalty_usd <- monetary_penalty_tidy %>%
  mutate(
    monetary_penalty_usd = if_else(str_to_upper(currency) == "USD",
                                   monetary_penalty,
                                   NA_real_)
  )
```

#### Step 4:

```{r professional-sanction-tidy}

ai_data <- ai_data |>
  mutate(
    professional_sanction = case_when(
      str_detect(professional_sanction, regex("yes|y", ignore_case = TRUE)) ~ "Yes",
      str_detect(professional_sanction, regex("no|n", ignore_case = TRUE)) ~ "No",
      TRUE ~ professional_sanction
    )
  )

```

## Plots

### ggsave example for saving plots

```{r starwars ggsave example}
p1 <- starwars |>
  filter(mass < 1000, 
         species %in% c("Human", "Cerean", "Pau'an", "Droid", "Gungan")) |>
  ggplot() +
  geom_point(aes(x = mass, 
                 y = height, 
                 color = species)) +
  labs(x = "Weight (kg)", 
       y = "Height (m)",
       color = "Species",
       title = "Weight and Height of Select Starwars Species",
       caption = paste("This data comes from the starwars api: https://swapi.py43.com"))


ggsave("example-starwars.png", width = 4, height = 4)

ggsave("example-starwars-wide.png", width = 6, height = 4)
```


### Plot 1: Trend of AI Hallucination Cases by Most Used LLM (2023-2025)

#### Plot 1 Data Cleanup

```{r ai-tool-cleanup}

### Standardizing Text
ai_tool_tidy <- ai_data |>
  mutate(ai_tool = str_replace_all(ai_tool, " and | & ", ",")) |>
  separate_rows(ai_tool, sep = ",|/|;") |>
  mutate(ai_tool = str_squish(ai_tool),
         ai_tool = na_if(ai_tool, ""),
         ai_tool = if_else(str_to_lower(ai_tool) %in% c("n/a","na","none"), NA_character_, ai_tool)) |>
  drop_na(ai_tool)

### Settings Synonyms
synonyms <- c(
  "ChatGPT" = "OpenAI ChatGPT",
  "GPT-4" = "OpenAI ChatGPT",
  "GPT4" = "OpenAI ChatGPT",
  "Google Gemini" = "Gemini",
  "Google Bard" = "Gemini",
  "Bard" = "Gemini",
  "Claude" = "Anthropic Claude",
  "implied" = "Implied",
  "Copilot" = "MS Copilot",
  "Microsoft CoPilot" = "MS Copilot",
  "CoPilot" = "MS Copilot"
)
ai_tool_tidy <- ai_tool_tidy |>
  mutate(ai_tool = coalesce(synonyms[ai_tool], ai_tool))

```

#### Final Plot 1

```{r plot-one}

```

### Plot 2: AI Hallucination Cases and Corresponding Outcome by State

#### Plot 2 Data Cleanup

##### Step 1:

```{r court-location-cleanup}

ai_data <- ai_data |>
  mutate(
    court_location = case_when(
      str_detect(court_location, regex("Iowa", ignore_case = TRUE)) ~ "Iowa",
      str_detect(court_location, regex("Alabama", ignore_case = TRUE)) ~ "Alabama",
      str_detect(court_location, regex("Arizona", ignore_case = TRUE)) ~ "Arizona",
      str_detect(court_location, regex("Arkansas", ignore_case = TRUE)) ~ "Arkansas",
      str_detect(court_location, regex("California|Fifth|Cal.|3rd|Cal|2nd|9th", ignore_case = TRUE)) ~ "California",
      str_detect(court_location, regex("Colorado", ignore_case = TRUE)) ~ "Colorado",
      str_detect(court_location, regex("Connecticut", ignore_case = TRUE)) ~ "Connecticut",
      str_detect(court_location, regex("Florida", ignore_case = TRUE)) ~ "Florida",
      str_detect(court_location, regex("Georgia|Ga.", ignore_case = TRUE)) ~ "Georgia",
      str_detect(court_location, regex("Hawaii|Hawai'i", ignore_case = TRUE)) ~ "Hawaii",
      str_detect(court_location, regex("Idaho", ignore_case = TRUE)) ~ "Idaho",
      str_detect(court_location, regex("Illinois|Cook County|7th", ignore_case = TRUE)) ~ "Illinois",
      str_detect(court_location, regex("Indiana|Ind.", ignore_case = TRUE)) ~ "Indiana",
      str_detect(court_location, regex("Kansas", ignore_case = TRUE)) ~ "Kansas",
      str_detect(court_location, regex("Kentucky", ignore_case = TRUE)) ~ "Kentucky",
      str_detect(court_location, regex("Louisiana", ignore_case = TRUE)) ~ "Louisiana",
      str_detect(court_location, regex("Maine", ignore_case = TRUE)) ~ "Maine",
      str_detect(court_location, regex("Maryland", ignore_case = TRUE)) ~ "Maryland",
      str_detect(court_location, regex("Massachusetts", ignore_case = TRUE)) ~ "Massachusetts",
      str_detect(court_location, regex("Michigan|Mich.", ignore_case = TRUE)) ~ "Michigan",
      str_detect(court_location, regex("Minnesota|Minnesotta", ignore_case = TRUE)) ~ "Minnesota",
      str_detect(court_location, regex("Mississippi|Miss.", ignore_case = TRUE)) ~ "Mississippi",
      str_detect(court_location, regex("Missouri", ignore_case = TRUE)) ~ "Missouri",
      str_detect(court_location, regex("Montana", ignore_case = TRUE)) ~ "Montana",
      str_detect(court_location, regex("Nebraska", ignore_case = TRUE)) ~ "Nebraska",
      str_detect(court_location, regex("Nevada|Nev.", ignore_case = TRUE)) ~ "Nevada",
      str_detect(court_location, regex("New Hampshire", ignore_case = TRUE)) ~ "New Hampshire",
      str_detect(court_location, regex("New Mexico", ignore_case = TRUE)) ~ "New Mexico",
      str_detect(court_location, regex("New Jersey", ignore_case = TRUE)) ~ "New Jersey",
      str_detect(court_location, regex("New York|E.d.n.y.|N.y.|S.d.n.y.|Kings County|Ndny|Ny|Supreme Court, Ny|Sdny", ignore_case = TRUE)) ~ "New York",
      str_detect(court_location, regex("North Carolina|N. Carolina|N.c.", ignore_case = TRUE)) ~ "North Carolina",
      str_detect(court_location, regex("North Dakota", ignore_case = TRUE)) ~ "North Dakota",
      str_detect(court_location, regex("Ohio", ignore_case = TRUE)) ~ "Ohio",
      str_detect(court_location, regex("Oklahoma", ignore_case = TRUE)) ~ "Oklahoma",
      str_detect(court_location, regex("Oregon", ignore_case = TRUE)) ~ "Oregon",
      str_detect(court_location, regex("Pennsylvania|Penn.|Pa.", ignore_case = TRUE)) ~ "Pennsylvania",
      str_detect(court_location, regex("Rhode Island", ignore_case = TRUE)) ~ "Rhode Island",
      str_detect(court_location, regex("South Carolina|Sc|S.c.", ignore_case = TRUE)) ~ "South Carolina",
      str_detect(court_location, regex("South Dakota", ignore_case = TRUE)) ~ "South Dakota",
      str_detect(court_location, regex("Tennessee", ignore_case = TRUE)) ~ "Tennessee",
      str_detect(court_location, regex("Texas|Tex.", ignore_case = TRUE)) ~ "Texas",
      str_detect(court_location, regex("Utah", ignore_case = TRUE)) ~ "Utah",
      str_detect(court_location, regex("Vermont", ignore_case = TRUE)) ~ "Vermont",
      str_detect(court_location, regex("Virginia|Gao|Ocaho|Dc|Federal Claims|(Gao)|Tax Court|Fed. Claims|D.c.", ignore_case = TRUE)) ~ "Virginia",
      str_detect(court_location, regex("Washington", ignore_case = TRUE)) ~ "Washington",
      str_detect(court_location, regex("West Virginia", ignore_case = TRUE)) ~ "West Virginia",
      str_detect(court_location, regex("Wisconsin|Ho-Chunk", ignore_case = TRUE)) ~ "Wisconsin",
      str_detect(court_location, regex("Wyoming", ignore_case = TRUE)) ~ "Wyoming",
      str_detect(court_location, regex("Puerto Rico|Primera", ignore_case = TRUE)) ~ "Puerto Rico",
      str_detect(court_location, regex("High Court|Alberta|Frankfurt|Ontario|Family|Nsw|Buenos|Civil|Supreme|Court|Victoria|Review|Rotterdam|Icsid|Rosario|Employment|Immigration|Columbia|Paulo|Chancery|Resolution|Fair Work|Jerusalem|Ontario's|Ottawa|Intellectual|Parana|Queensland|Israel|Uk|Supremo|Housing|Olg|Crt|Florence|Australia|Constitucional|Hague|Manchester|Torino", ignore_case = TRUE)) ~ "International",
      TRUE ~ court_location
    )
  )

```

##### Step 2:

```{r outcome-cleanup}

ai_data <- ai_data |>
  mutate(
    outcome = case_when(
      str_detect(outcome, regex("Warning|Opportunity|No Contempt|Warned|Caution|Reprimand|Reminder|Refile|Corrections|Exclude|Criticised|Reprimand|Court Imposed", ignore_case = TRUE)) ~ "Warning",
      str_detect(outcome, regex("dismissed|thrown out|Accepted|Excluded|Rejected|Discharged|Dismiss|Sworn|Withdrew|Removed|Stricken|Striking|Ignored|Struck|Disregarded|Irrelevant|Dismissal|Inadmissible|Admonishment|No Weight|Striking|Adjourned|Withdrawn", ignore_case = TRUE)) ~ "Dismissed",
      str_detect(outcome, regex("pending|Under Review|Re-Heard|Osc|ongoing|Tenatively|Referral|3 hours|Referred", ignore_case = TRUE)) ~ "Pending",
      str_detect(outcome, regex("Apologize|Lost On Merits|fined|Lost|sanction|penalty|Fine|costs|Cause|cause|Pay|Costs|Costas|Denied|Community Service|Contempt|Cle Course|Reimburse|Ethics|Fine|Lesser Weight|Treated|Compensated|Liability|Refused|Suspension|Mandantory|Undergo", ignore_case = TRUE)) ~ "Penalized",
      TRUE ~ outcome
    )
  )

```

#### Final Plot 2

```{r plot-two}

```

### Plot 3: Top 5 Hallucination Types by Outcome

#### Plot 3 Data Cleanup

##### Step 1:

```{r hallucination-cleanup}

ai_data <- ai_data |>
  mutate(
    hallucination = case_when(
      str_detect(coalesce(hallucination, ""), regex("Miscited|Case Cited|citation|Cittions", ignore_case = TRUE)) ~ "Fake Citation",
      str_detect(coalesce(hallucination, ""), regex("Chatgpt-Generated|Irrelevant Info|Paragraph|argument|Authority",  ignore_case = TRUE)) ~ "Fake Argument",
      str_detect(coalesce(hallucination, ""), regex("Inaccuracies|Quotation|Quotations|References|quote|source|evidentiary|evidence", ignore_case = TRUE)) ~ "Fake Source/Quote",
      str_detect(coalesce(hallucination, ""), regex("Non-Existent Legal|Wrong Legal|Caselaw|case law", ignore_case = TRUE)) ~ "Fabricated Case Law",
      str_detect(coalesce(hallucination, ""), regex("norm", ignore_case = TRUE)) ~ "Fabricated Norm",
      str_detect(coalesce(hallucination, ""), regex("Fake/Incorrect|Nonexistent Cases|Non-Existent Israeli|Irrelevant Cases|Fake Legal Case|Fictitious Cases|Non-Existent Case|Or Misrepresented Cases|Non-Existent Cases|Fabricated Cases|Fake Cases|Fake Case|Fake/Flawed Cases|Fictitious Court", ignore_case = TRUE)) ~ "Fabricated Case",
      str_detect(coalesce(hallucination, ""), regex("Misrepresented Facts|Precedent", ignore_case = TRUE)) ~ "Misrepresented Fact / Precedent",
      str_detect(coalesce(hallucination, ""), regex("Legal Authorities|Fictitious Authorities|Tribunal|Outdated Advice|Fictitious Legal|Court Decisions|Misattributed Court Decisions|Fictitious Court|Fictitious Judgement|Legal Judgments|Judgements", ignore_case = TRUE)) ~ "False Legal Judgments",
      str_detect(coalesce(hallucination, ""), regex("Suspicious|Unverifiable|Allegations|Pseudolegal|None", ignore_case = TRUE)) ~ "Unable to Conclude AI-Generated Content",
      str_detect(coalesce(hallucination, ""), regex("Fabricated Attribution", ignore_case = TRUE)) ~ "Fabricated Attribution",
      str_detect(coalesce(hallucination, ""), regex("Appeal", ignore_case = TRUE)) ~ "Fake Appeal Brief",
      TRUE ~ hallucination
    )
  )

```

##### Step 2:

```{r plot-three-general-cleanup}

library(tidyverse)
library(scales)
library(forcats)


ai_data <- ai_data |>
  mutate(
    outcome = str_squish(outcome),
    outcome = na_if(outcome, "NA"),
    outcome = na_if(outcome, "N/A"),
    outcome = na_if(outcome, "None"),
    outcome = na_if(outcome, "")
  )

top5_hallucinations <- ai_data |>
  filter(!is.na(hallucination)) |>
  count(hallucination, sort = TRUE) |>
  distinct(hallucination, .keep_all = TRUE) |>
  slice_head(n = 5) |>
  pull(hallucination) |>
  unique()


hall_outcome <- ai_data |>
  filter(
    hallucination %in% top5_hallucinations,
    !is.na(outcome)
  ) |>
  droplevels() |> 
  count(outcome, hallucination, name = "n_cases") |>
  group_by(outcome) |>
  mutate(
    pct_within_outcome = n_cases / sum(n_cases),
    total_cases        = sum(n_cases)
  ) |>
  ungroup() |>
  mutate(
    hallucination = factor(hallucination,
                           levels = unique(top5_hallucinations)) 
  )

```

#### Final Plot 3

```{r plot-three}

```



