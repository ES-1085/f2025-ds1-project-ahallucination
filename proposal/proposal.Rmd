---
title: "Project proposal"
author: "AI Hallunication Cases - Yuka, Brynn, & Sasha"
output: github_document
---

```{r load-packages, message = FALSE}
library(tidyverse)
library(broom)
ai_data <- read_csv("../data/Charlotin-hallucination_cases.csv")
#view(ai_data)
```

## 1. Introduction

We found our data set on Kaggle, and it was contributed by a man named Damien Charlotin. He is a senior research fellow, specifically on artificial intelligence and the law. He is also a lecturer and independent practitioner in Paris. The AI hallucinations dataset contains cases from across the world from 2023 to 2025. The dataset keeps a record of legal cases in which AI was used and found to be wrong. Generative AI produced incorrect citations as well as other fake arguments. The dataset contains the case, the type of hallucination, the type of AI, the outcome of the case, the monetary penalty, the state, the time, etc. Our data is set up nicely, where each observation directly translates to a specific court case that is listed by name. A LLM refers to a “large language model”. This represents the type of AI used whether it was chat GPT, Gemini, etc. A hallucination is when one of these LLMs basically produces an incorrect output or provides the user with something nonsensical. Our data also includes a variable, monetary penalty, which lists how much each “error” in a specific LLM is penalized. The study in which the data was collected is relatively new. There are currently 426 cases where generative AI has been used, however, this dataset is still expanding as more come to light. Note that this study is a work in progress and doesn’t contain all court cases in which AI was used. It is noted on Kaggle that the data will be updated annually with new findings. We were mainly interested in when these cases started emerging, what forms of AI were being used the most, and how some of our variables like party and hallucination type, affect monetary penalty.Some of our research questions we want to examine further are:

1.  Which states come up the most with AI hallucinations?
2.  What LLM is being used the most?
3.  What year did cases start to spike?
4.  What AI hallucinations have a higher monetary penalty?
5.  What effect did the party type have on the outcome and monetary penalty within each case?

## 2. Data

**Renaming Variables**

```{r rename-variables}
ai_data <- as_tibble(ai_data) |>
  rename(
`case_name` = `Case Name`,
`court` = `Court`,
`state` = `State(s)`,
`date` = `Date`,
`party` = `Party(ies)`,
`ai_tool` = `AI Tool`,
`hallucination` = `Hallucination`,
`outcome` = `Outcome`,
`monetary_penalty` = `Monetary Penalty`,
`professional_sanction` = `Professional Sanction`,
`key_principle` = `Key Principle`,
`pointer` = `Pointer`,
`source` = `Source`,
`details` = `Details`
)
```

**Data Cleanup**

Since we have very little numerical data, we need to first clean up our dataset before we visualize. We focused specifically on cleaning the variables we are analyzing: court, location, ai_tool, hallucination, outcome, monetary_penalty.

First, we removed all extra spaces, standardized the capitalization, and converted all empty observations to NA for all of our variables of interest. Next, we did the same focusing specifically on ai_tool, splitting rows based on common separators such as slashes, colons, and commas. After tidying these data, we accounted for synonyms, and finally did a wordcount for each of the tools mentioned. Then, we focused specifically on monetary_penalty, and removed all non-numeric characters, replaced any text indicative of a missing value with NA, and turned the numbers into an actual number type. Finally, for the variables hallucination, outcome, and professional_sanction, we used keywords to group text (ignoring capitalization) and replace it with a standard word or phrase.

```{r data-cleanup}
ai_data <- ai_data |>
  mutate(
    across(
      c(court, state, hallucination, outcome, monetary_penalty, professional_sanction),
      ~ .x |> str_squish() |> str_to_title() |> na_if("")
    )
  )

rates <- tibble::tribble(
  ~currency, ~rate_to_usd,
  "USD", 1,
  "EUR", 1.07,
  "GBP", 1.24,
  "CAD", 0.73
)

ai_data <- ai_data %>% 
  mutate(currency = "USD")


monetary_penalty_tidy <- ai_data %>%
  mutate(
    monetary_penalty = str_replace_all(monetary_penalty, "[$,]", ""),
    monetary_penalty = na_if(monetary_penalty, "none"),
    monetary_penalty = na_if(monetary_penalty, "n/a"),
    monetary_penalty = na_if(monetary_penalty, "na"),
    monetary_penalty = na_if(monetary_penalty, "N/A"),
    monetary_penalty = as.numeric(monetary_penalty)
  )

monetary_penalty_usd <- monetary_penalty_tidy %>%
  mutate(
    monetary_penalty_usd = if_else(str_to_upper(currency) == "USD",
                                   monetary_penalty,
                                   NA_real_)
  )
```

```{r ai-tool-tidy}
ai_tool_tidy <- ai_data |>
  mutate(ai_tool = str_replace_all(ai_tool, " and | & ", ",")) |>
  separate_rows(ai_tool, sep = ",|/|;") |>
  mutate(ai_tool = str_squish(ai_tool),
         ai_tool = na_if(ai_tool, ""),
         ai_tool = if_else(str_to_lower(ai_tool) %in% c("n/a","na","none"), NA_character_, ai_tool)) |>
  drop_na(ai_tool)
```

```{r ai-tool-synonyms}

synonyms <- c(
  "ChatGPT" = "OpenAI ChatGPT",
  "GPT-4" = "OpenAI ChatGPT",
  "GPT4" = "OpenAI ChatGPT",
  "Google Gemini" = "Gemini",
  "Google Bard" = "Gemini",
  "Bard" = "Gemini",
  "Claude" = "Anthropic Claude",
  "implied" = "Implied",
  "Copilot" = "MS Copilot",
  "Microsoft CoPilot" = "MS Copilot",
  "CoPilot" = "MS Copilot"
)
ai_tool_tidy <- ai_tool_tidy |>
  mutate(ai_tool = coalesce(synonyms[ai_tool], ai_tool))

```

```{r ai-tool-word-counts}
word_counts <- ai_tool_tidy |>
  count(ai_tool, name = "freq", sort = TRUE)
```

```{r mutate-variables}
ai_data <- ai_data |>
  mutate(
    hallucination = case_when(
      str_detect(coalesce(hallucination, ""), regex("citation", ignore_case = TRUE)) ~ "Fake Citation",
      str_detect(coalesce(hallucination, ""), regex("argument",  ignore_case = TRUE)) ~ "Fake Argument",
      str_detect(coalesce(hallucination, ""), regex("quote|source|evidentiary|evidence", ignore_case = TRUE)) ~ "Fake Source/Quote",
      str_detect(coalesce(hallucination, ""), regex("Caselaw|case law", ignore_case = TRUE)) ~ "Fabricated Case Law",
      str_detect(coalesce(hallucination, ""), regex("norm", ignore_case = TRUE)) ~ "Fabricated Norm",
      str_detect(coalesce(hallucination, ""), regex("Fabricated Cases|Fake Cases|Fake Case|Fake/Flawed Case", ignore_case = TRUE)) ~ "Fabricated Case",
      str_detect(coalesce(hallucination, ""), regex("Misrepresented", ignore_case = TRUE)) ~ "Fabricated Norm",
      TRUE ~ hallucination
    )
    
# first is key words youre searching for, second is new name

  )
ai_data <- ai_data |>
  mutate(
    outcome = case_when(
      str_detect(outcome, regex("dismissed|thrown out", ignore_case = TRUE)) ~ "Dismissed",
      str_detect(outcome, regex("pending|ongoing", ignore_case = TRUE)) ~ "Pending",
      str_detect(outcome, regex("fined|sanction|penalty", ignore_case = TRUE)) ~ "Penalized",
      TRUE ~ outcome
    )
  )
ai_data <- ai_data |>
  mutate(
    professional_sanction = case_when(
      str_detect(professional_sanction, regex("yes|y", ignore_case = TRUE)) ~ "Yes",
      str_detect(professional_sanction, regex("no|n", ignore_case = TRUE)) ~ "No",
      TRUE ~ professional_sanction
    )
  )
```

```{r dimensions}
print(dim(ai_data))
```

```{r glimpse}
print(glimpse(ai_data))
```

```{r specs}
print(spec(ai_data))
```

## 3. Data analysis plan

-   What variables will you visualize to explore your research questions?

court -> We will explore whether or not any patterns arise between the specific court and the severity of the punishment, or rather if there are certain courts that try more ai hallucination cases than others

location -> We will observe if there is any relationship between location and the frequency of cases

ai_tool -> Do certain ai tools/softwares appear in these cases more often? Are certain awarded larger penalties?

hallucination -> What were the most common hallucinations in these cases? Were there specific ai tools that were ore often responsible for certain hallucinations?

outcome -> What were the most common outcomes for these cases, and do they vary by location, ai tool used, court tries in, or the specific hallucination?

monetary_penatly -> What was the range of monetary penalties for these cases? What is considered on the high end and what hallucinations led to these penalties?

professional_sanction -> What is the relationship between monetary penalty and whether or not professional disciplinary action was taken against the party involved?

-   Will there be any other data that you need to find to help with your research question?

As of now, we don't think so. However, we might need to find other data as we explore our research questions further.

## 3. Preliminary Visualizations

**Summary Statistics**

```{r summary_stats}
summary(ai_data$monetary_penalty)
```

**Preliminary Visualization**

```{r visualizations}

ai_data$monetary_penalty <- as.numeric(ai_data$monetary_penalty)

word_counts <- ai_data |>
  count(ai_tool, sort = TRUE)

ggplot(ai_data, aes(x = monetary_penalty)) +
  geom_histogram(bins = 30, fill = "red", color = "white") +
  labs(
    title = "Distribution of Monetary Penalties",
    x = "Penalty Amount (USD)",
    y = "Number of Cases"
  ) +
  theme_minimal()


ai_data |>
  count(state, sort = TRUE) |>
  slice_max(n, n = 10) |>
  ggplot(aes(x = reorder(state, n), y = n)) +
  geom_col(fill = "pink") +
  coord_flip() +
  labs(title = "Top 10 States by Number of AI Hallucination Cases",
       x = "State", y = "Number of Cases") +
  theme_minimal()


ggplot(ai_data, aes(x = state, fill = monetary_penalty)) +
  geom_bar(color = "white") +
  labs(
    title = "Amount of Cases per State",
    x = "State",
    y = "Number of Cases", 
    fill = "Penalty Amount (USD)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(ai_data, aes(x = party, fill = monetary_penalty)) +
  geom_bar(color = "white") +
  labs(
    title = "monetary penalty per party",
    x = "Party",
    y = "Monetary Penalty (USD)", 
    fill = "Penalty Amount (USD)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggplot(ai_data, aes(x = party, y = monetary_penalty, fill = party)) +
  geom_boxplot(color = "black") +
  labs(
    title = "Distribution of Monetary Penalties per Party",
    x = "Party",
    y = "Monetary Penalty (USD)",
    fill = "Party"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )






```








